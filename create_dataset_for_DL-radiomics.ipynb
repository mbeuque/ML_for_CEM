{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,re,random,time,sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "import SimpleITK as sitk\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from skimage.measure import regionprops,label\n",
    "from time import time\n",
    "import os,re,random\n",
    "from tqdm import tqdm\n",
    "from math import sqrt\n",
    "from PIL import Image\n",
    "from skimage import exposure\n",
    "import random "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contains index (unique token of the image), path_recombined_img, path_low_energy_img, path_mask_img, outcome\n",
    "df_train = pd.read_excel('all_info_train_dataset.xlsx',index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## making the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fct_generate_figures(temp_img):\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.imshow(temp_img, cmap='gray')\n",
    "    plt.show()\n",
    "    fig1 = sns.displot(temp_img.flatten(), element=\"step\",bins=50)\n",
    "    fig1.fig.set_figwidth(11)\n",
    "    fig1.fig.set_figheight(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_img_experiment_with_sergey(img_read_re, img_read_le, msk_read,generate_figures=None):\n",
    "    otsu = sitk.OtsuThresholdImageFilter()\n",
    "    otsu_image = otsu.Execute(img_read_re)\n",
    "    otsu_array = sitk.GetArrayFromImage(otsu_image)\n",
    "    \n",
    "    invert_otsu = (np.ones(otsu_array.shape)-otsu_array).astype(np.uint8)\n",
    "    (contours,_) = cv2.findContours(invert_otsu, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    max_ctr = contours[0]\n",
    "    for ctr in contours:\n",
    "        if cv2.contourArea(ctr) > cv2.contourArea(max_ctr):\n",
    "            max_ctr= ctr\n",
    "    img_temp = np.zeros(invert_otsu.shape)\n",
    "    polygon = ctr\n",
    "    cv2.fillPoly( img_temp, [max_ctr], [1] )\n",
    "    otsu_array = np.ones(invert_otsu.shape)-img_temp\n",
    "    \n",
    "    if generate_figures=='le' or generate_figures=='re':\n",
    "        fct_generate_figures(img_temp)\n",
    "        \n",
    "    temp_img_re = sitk.GetArrayFromImage(img_read_re)\n",
    "    \n",
    "    if generate_figures=='re':\n",
    "        fct_generate_figures(temp_img_re)\n",
    "    \n",
    "    temp_img_le_original = sitk.GetArrayFromImage(img_read_le)\n",
    "    \n",
    "    if generate_figures=='le':\n",
    "        fct_generate_figures(temp_img_le_original)\n",
    "        \n",
    "    temp_msk = sitk.GetArrayFromImage(msk_read)\n",
    "    temp_img_re =(np.ones((img_read_re.GetSize()[1], img_read_re.GetSize()[0]))-otsu_array)*temp_img_re\n",
    "    temp_img_le =(np.ones((img_read_le.GetSize()[1], img_read_le.GetSize()[0]))-otsu_array)*temp_img_le_original\n",
    "    props = regionprops(np.array(temp_img_re>0,np.uint8))\n",
    "    r0, c0, r1, c1 = props[0].bbox\n",
    "    temp_img_re = temp_img_re[r0:r1, c0:c1]\n",
    "    \n",
    "    if generate_figures=='re':\n",
    "        fct_generate_figures(temp_img_re)\n",
    "    \n",
    "    if generate_figures=='re':\n",
    "        fct_generate_figures(temp_img_re)\n",
    "    \n",
    "    temp_img_re = pre_processing_for_img(temp_img_re)\n",
    "    \n",
    "    if generate_figures=='re':\n",
    "        fct_generate_figures(temp_img_re)\n",
    "    \n",
    "    temp_img_le = temp_img_le[r0:r1, c0:c1]\n",
    "    \n",
    "    if generate_figures=='le':\n",
    "        fct_generate_figures(temp_img_le)\n",
    "    \n",
    "    temp_img_le = pre_processing_for_img(temp_img_le)\n",
    "    \n",
    "    if generate_figures=='le':\n",
    "        fct_generate_figures(temp_img_le)\n",
    "\n",
    "    \n",
    "    temp_msk =temp_msk[r0:r1, c0:c1]\n",
    "\n",
    "    return temp_img_re, temp_img_le,temp_msk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_intensities(orig_img,bin_nr=256):            ## Intensity resampling whole image/or masked region\n",
    "    v_count=0\n",
    "    img_list=[]\n",
    "    filtered = orig_img.copy()\n",
    "    if np.min(orig_img.flatten())<0:\n",
    "        filtered+=np.min(orig_img.flatten())\n",
    "    resampled = np.zeros_like(filtered)\n",
    "    max_val_img = np.max(filtered.flatten())\n",
    "    min_val_img = np.min(filtered.flatten())\n",
    "    step = (max_val_img-min_val_img)/bin_nr\n",
    "\n",
    "    for st in np.arange(step+min_val_img,max_val_img+step,step):\n",
    "        resampled[(filtered<=st)&(filtered>=st-step)] = v_count\n",
    "        v_count+=1\n",
    "    \n",
    "    print(\"Resampling with a step of: \",step ,'Amount of unique values, original img: ',len(np.unique(orig_img.flatten())),'resampled img: ',len(np.unique(resampled.flatten())))\n",
    "    return np.array(resampled,dtype=np.uint16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing_for_img(img):\n",
    "    temp_img = img.copy()\n",
    "    low_thr = np.quantile(temp_img[temp_img>0], 0.01)\n",
    "    high_thr = np.quantile(temp_img[temp_img>0], 0.99)\n",
    "    temp_img[temp_img<low_thr] = low_thr\n",
    "    temp_img[temp_img>high_thr] = high_thr\n",
    "    if len(np.unique(temp_img[temp_img>0])) > 256:\n",
    "            temp_img_sampled = resample_intensities(temp_img[temp_img>0])\n",
    "            temp_img[temp_img>0] = temp_img_sampled\n",
    "    else:\n",
    "        new_img =(temp_img-np.min(temp_img))/(np.max(temp_img)-np.min(temp_img)) \n",
    "        temp_img = (new_img*255).astype(np.uint8)\n",
    "    return temp_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "def load_patient_experiment(dataframe, filename,generate_figures=None):\n",
    "    img_read_re = sitk.ReadImage(list(dataframe[dataframe['Unnamed: 0'] == filename]['path_recombined_img'])[0])\n",
    "    img_read_le = sitk.ReadImage(list(dataframe[dataframe['Unnamed: 0'] == filename]['path_low_energy_img'])[0])\n",
    "    #img_read_le = img_read_le[:,:,0] \n",
    "    msk_read = sitk.ReadImage(list(dataframe[dataframe['Unnamed: 0'] == filename]['path_mask_img'])[0])\n",
    "\n",
    "    img_re, img_le, msk = crop_img_experiment_with_sergey(img_read_re, img_read_le, msk_read,generate_figures)\n",
    "    props_msk = regionprops(np.array(msk>0,np.uint8))\n",
    "    final_msk = np.array(msk>0,np.uint8)\n",
    "    is_empty = 1 - np.any(final_msk).astype(int)\n",
    "    return img_le,img_re, props_msk, final_msk,is_empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_clipped_values(img_read_re, img_read_le):\n",
    "    otsu = sitk.OtsuThresholdImageFilter()\n",
    "    otsu_image = otsu.Execute(img_read_re)\n",
    "    otsu_array = sitk.GetArrayFromImage(otsu_image)\n",
    "    \n",
    "    invert_otsu = (np.ones(otsu_array.shape)-otsu_array).astype(np.uint8)\n",
    "    (contours,_) = cv2.findContours(invert_otsu, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    max_ctr = contours[0]\n",
    "    for ctr in contours:\n",
    "        if cv2.contourArea(ctr) > cv2.contourArea(max_ctr):\n",
    "            max_ctr= ctr\n",
    "    img_temp = np.zeros(invert_otsu.shape)\n",
    "    polygon = ctr\n",
    "    cv2.fillPoly( img_temp, [max_ctr], [1] )\n",
    "    otsu_array = np.ones(invert_otsu.shape)-img_temp\n",
    "    \n",
    "    temp_img_re = sitk.GetArrayFromImage(img_read_re)\n",
    "    temp_img_le = sitk.GetArrayFromImage(img_read_le)\n",
    "    array_air_re = otsu_array*temp_img_re\n",
    "    median_re = np.median(array_air_re[array_air_re > 0])\n",
    "    array_air_le = otsu_array*temp_img_le\n",
    "    median_le = np.median(array_air_le[array_air_le > 0])\n",
    "    temp_img_re =(np.ones((img_read_re.GetSize()[1], img_read_re.GetSize()[0]))-otsu_array)*temp_img_re\n",
    "    temp_img_le =(np.ones((img_read_le.GetSize()[1], img_read_le.GetSize()[0]))-otsu_array)*temp_img_le\n",
    "    temp_img_re[temp_img_re == 0] = median_re\n",
    "    low_thr_re = np.quantile(temp_img_re[temp_img_re>median_re], 0.01)\n",
    "    high_thr_re = np.quantile(temp_img_re[temp_img_re>median_re], 0.99)\n",
    "    temp_img_re[temp_img_re<low_thr_re] = low_thr_re\n",
    "    temp_img_re[temp_img_re>high_thr_re] = high_thr_re\n",
    "    \n",
    "    temp_img_le[temp_img_le == 0] = median_le\n",
    "    low_thr_le = np.quantile(temp_img_le[temp_img_le>median_le], 0.01)\n",
    "    high_thr_le = np.quantile(temp_img_le[temp_img_le>median_le], 0.99)\n",
    "    temp_img_le[temp_img_le<low_thr_le] = low_thr_le #maybe should be better adapted, with the mean of pixels below 90% of the breast values \n",
    "    temp_img_le[temp_img_le>high_thr_le] = high_thr_le\n",
    "    \n",
    "    return [low_thr_re,high_thr_re],[low_thr_le,high_thr_le]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clahe = cv2.createCLAHE(clipLimit =2.5, tileGridSize=(16,16))\n",
    "clahe_recombined_2 = cv2.createCLAHE(clipLimit =1.0, tileGridSize=(16,16)) #are they the best parameters?\n",
    "ext_filenames = list(df_train['Unnamed: 0'])\n",
    "list_coord = []\n",
    "list_train_not_done = []\n",
    "for i,filename in tqdm(enumerate(ext_filenames)):\n",
    "    generate_figures=False\n",
    "    img_le, img_re, props_msk,final_msk,is_empty = load_patient_experiment(df_train,filename,generate_figures)\n",
    "    if len(props_msk)==0 and is_empty==1: #we select only the images which don't contains a mask\n",
    "        new_img_le =(img_le-np.min(img_le))/(np.max(img_le)-np.min(img_le)) \n",
    "        im_le = (new_img_le*255).astype(np.uint8)\n",
    "\n",
    "        x_le = clahe.apply(im_le).astype(np.uint8)\n",
    "        new_img_re =(img_re-np.min(img_re))/(np.max(img_re)-np.min(img_re)) \n",
    "        new_img_re = (new_img_re*255).astype(np.uint8)\n",
    "        \n",
    "#         if generate_figures=='le':\n",
    "#             fct_generate_figures(im_le)\n",
    "            \n",
    "#         if generate_figures=='re':\n",
    "#             fct_generate_figures(new_img_re)\n",
    "        \n",
    "        x_re = clahe.apply(new_img_re).astype(np.uint8)\n",
    "        \n",
    "#         if generate_figures=='re':\n",
    "#             fct_generate_figures(x_re)\n",
    "\n",
    "        x_re_2 = clahe_recombined_2.apply(new_img_re).astype(np.uint8)\n",
    "        \n",
    "#         if generate_figures=='re':\n",
    "#             fct_generate_figures(x_re_2)\n",
    "        \n",
    "        temp_im_le = Image.fromarray(x_le)\n",
    "        temp_im_re = Image.fromarray(x_re)\n",
    "        temp_im_re_2 = Image.fromarray(x_re_2)\n",
    "        #temp_mask_png = Image.fromarray(mask2)\n",
    "        temp_name_le = ##\n",
    "        temp_name_re = ##\n",
    "        #temp_name_mask = ##\n",
    "        temp_name_re_2 =##\n",
    "\n",
    "#         temp_im_le.save(temp_name_le)\n",
    "#         temp_im_re.save(temp_name_re)\n",
    "#         temp_im_re_2.save(temp_name_re_2)\n",
    "        #temp_mask_png.save(temp_name_mask)\n",
    "        list_coord.append([r\"\"+\",,,,,\"+str(list(df_train[df_train['Unnamed: 0'] == filename]['outcome'])[0])+\",\"])\n",
    "    else:\n",
    "        list_train_not_done.append(filename)\n",
    "        print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(redone_list, columns=[\"filename\",\"x1\",\"y1\",\"x2\",\"y2\",\"labels\",\"path_mask\"])\n",
    "df.to_csv(\"annotations_train_dataset.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ext_filenames = list(df_train['Unnamed: 0'])\n",
    "\n",
    "for i,filename in tqdm(enumerate(ext_filenames)):\n",
    "    temp_name_le = \"low_energy_to_jpg\\\\\"+filename+\".jpg\"\n",
    "    temp_name_re = \"recombined_to_jpg\\\\\"+filename+\".jpg\"\n",
    "    temp_name_re_2 = \"recombined_2_to_jpg\\\\\"+filename+\".jpg\"\n",
    "    temp_name_3channels = \"colored_to_jpg\\\\\" + filename + \".jpg\"\n",
    "\n",
    "    if os.path.exists(temp_name_re):\n",
    "        r = cv2.imread(temp_name_le,0)\n",
    "        g= cv2.imread(temp_name_re,0)\n",
    "        b =cv2.imread(temp_name_re_2,0)\n",
    "        img = cv2.merge((r,g,b))\n",
    "\n",
    "        cv2.imwrite(temp_name_3channels,img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
