{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import six\n",
    "from radiomics import featureextractor, getTestCase\n",
    "import pandas as pd\n",
    "import glob\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold, RandomizedSearchCV, train_test_split,StratifiedKFold\n",
    "from scipy.stats import uniform, randint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from missforest import MissForest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# first create dict with mask keys and value img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_training_msks_auto = glob.glob(\"train_dataset\\auto_generated_mask\\*.mha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_testing_masks_auto = glob.glob(\"test_dataset\\auto_generated_mask\\*.mha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_external_masks_auto = glob.glob(\"external_dataset\\auto_generated_mask\\*.mha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_true_msks = glob.glob(\"Breast segmentation\\MHAs\\*\\*\\*STRUCT1.mha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_images = glob.glob(\"Breast segmentation\\MHAs\\*\\*\\*RECOMBINED1.mha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_images_le = glob.glob(\"Breast segmentation\\MHAs\\*\\*\\*LOW_ENERGY1.mha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for auto prediction\n",
    "dict_paths_training_auto = {}\n",
    "empty_msk = []\n",
    "for temp_mask in tqdm.tqdm(path_training_msks_auto):\n",
    "    key_path = temp_mask.split(\"\\\\\")[-1][:-21]\n",
    "    pos = key_path.split(\"_\")[2]\n",
    "    view = key_path.split(\"_\")[-1]\n",
    "    tag_pat = key_path[:9]\n",
    "    for temp_mha in path_true_msks:\n",
    "        small_path_mha = temp_mha.split(\"\\\\\")[-1]\n",
    "        if tag_pat in small_path_mha and view+ \"_\" +pos in small_path_mha:\n",
    "            dict_paths_training_auto[temp_mask]=temp_mha\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_paths_training_auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dict_paths_training_auto.keys())[0].split(\"\\\\\")[-1].split(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_jpg = glob.glob(\"colored_to_jpg\\*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_patients= [temp.split(\"\\\\\")[-1][:9] for temp in all_train_jpg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_mha_train = [temp for temp in path_true_msks if temp.split(\"\\\\\")[-3] in train_patients]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create list of all the predictions associated to one mha\n",
    "path_masks_training_auto_copy = path_training_msks_auto.copy()\n",
    "dict_pred = {}\n",
    "path_masks_auto = list(dict_paths_training_auto.keys())\n",
    "for temp_ground_truth in tqdm.tqdm(list_mha_train):\n",
    "    list_pat_auto = []\n",
    "    for temp_mask in path_masks_training_auto_copy:\n",
    "        list_temp = temp_mask.split(\"\\\\\")[-1].split(\"_\")\n",
    "        patient_id = list_temp[0] + \"_\" + list_temp[1]\n",
    "        pos = list_temp[2]\n",
    "        view = list_temp[3]\n",
    "        if patient_id+\"_\" + view + \"_\" + pos in temp_ground_truth:\n",
    "            list_pat_auto.append(temp_mask)\n",
    "            path_masks_training_auto_copy.remove(temp_mask)\n",
    "    dict_pred[temp_ground_truth] = list_pat_auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv(\"train_set.csv\",names=[\"image_path\", \"x1\", \"y1\", \"x2\",\"y2\",\"outcome\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_path = list(train_csv['image_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(r'E:\\ManonData\\keras-retinanet-master\\auto_generated_labels.pck', 'wb') as handle:\n",
    "#     pickle.dump(labels, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create dict with image and true masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info_train = pd.read_excel('all_info_train_dataset.xlsx',index=True)\n",
    "path_train_imgs = list(df_info_train['path_recombined_img'])\n",
    "path_true_train_masks = list(df_info_train['path_mask_img'])\n",
    "outcome = list(df_info_train['outcome'])\n",
    "path_to_match = list(df_info_train['Unnamed: 0'])\n",
    "colored_imgs_path = os.listdir(\"colored_to_jpg\")\n",
    "small_colored_imgs_path = [temp[:-4] for temp in colored_imgs_path]\n",
    "dict_paths_true_train = {}\n",
    "true_train_outcome = []\n",
    "for i,temp_mask in enumerate(path_true_train_masks):\n",
    "    if path_to_match[i] in small_colored_imgs_path:\n",
    "        dict_paths_true_train[temp_mask] = path_train_imgs[i]\n",
    "        true_train_outcome.append(outcome[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(true_train_outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info_test = pd.read_excel('all_info_test_dataset.xlsx',index=True)\n",
    "path_test_imgs = list(df_info_test['path_recombined_img'])\n",
    "path_true_test_masks = list(df_info_test['path_mask_img'])\n",
    "outcome = list(df_info_test['outcome'])\n",
    "path_to_match = list(df_info_test['Unnamed: 0'])\n",
    "colored_imgs_path = os.listdir(\"colored_to_jpg\")\n",
    "small_colored_imgs_path = [temp[:-4] for temp in colored_imgs_path]\n",
    "dict_paths_true_test = {}\n",
    "true_test_outcome = []\n",
    "for i,temp_mask in enumerate(path_true_test_masks):\n",
    "    if path_to_match[i] in small_colored_imgs_path:\n",
    "        dict_paths_true_test[temp_mask] = path_test_imgs[i]\n",
    "        true_test_outcome.append(outcome[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(true_test_outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info_external = pd.read_excel(\"all_info_external_dataset.xlsx\",index=True)\n",
    "path_external_imgs = list(df_info_external['path_recombined_img'])\n",
    "path_true_external_masks = list(df_info_external['path_mask_img'])\n",
    "outcome = list(df_info_external['outcome'])\n",
    "path_to_match = list(df_info_external['Unnamed: 0'])\n",
    "colored_imgs_path = os.listdir(\"colored_to_jpg\")\n",
    "small_colored_imgs_path = [temp[:-4] for temp in colored_imgs_path]\n",
    "dict_paths_true_external = {}\n",
    "true_external_outcome = []\n",
    "for i,temp_mask in enumerate(path_true_external_masks):\n",
    "    if path_to_match[i] in small_colored_imgs_path:\n",
    "        dict_paths_true_external[temp_mask] = path_external_imgs[i]\n",
    "        true_external_outcome.append(outcome[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create dict with image and auto masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = \"annotations_train_dataset.csv\"\n",
    "df_train = pd.read_csv(train_csv,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels = list(df_train[5])\n",
    "key_struct = [elmt.split(\"\\\\\")[-1][:-4] for elmt in df_train[0]]\n",
    "reordered_key_struct = [elmt[:10]+elmt.split(\"_\")[-1] +\"_\"+ elmt[10] for elmt in key_struct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "path = \"dict_prediction_train.pkl\"\n",
    "with open(path, 'rb') as file:\n",
    "    try:\n",
    "        while True:\n",
    "            dict_prediction_train =  pickle.load(file)\n",
    "    except EOFError:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dict_paths_auto_mask_train = {}\n",
    "list_labels_auto_train=[]\n",
    "for temp_mask in tqdm.tqdm(path_training_msks_auto):\n",
    "    #key_path = temp_mask.split(\"\\\\\")[-1][:-12]\n",
    "    tag_pat = temp_mask.split(\"\\\\\")[-1][:9]+\"_\"+temp_mask.split(\"\\\\\")[-1][:-4].split(\"_\")[3]+\"_\"+temp_mask.split(\"\\\\\")[-1][:-4].split(\"_\")[2] \n",
    "    for temp_mha in path_images:\n",
    "        small_path_mha = temp_mha.split(\"\\\\\")[-1]\n",
    "        if tag_pat in small_path_mha and tag_pat in reordered_key_struct :\n",
    "            dict_paths_auto_mask_train[temp_mask]=temp_mha\n",
    "            for key in list(dict_prediction_train.keys()):\n",
    "                matching_path = key.split(\"\\\\\")[-1].split(\".\")[0] + \"_\" +key.split(\"\\\\\")[-1][-1] + \"_auto_rt_struct.mha\"\n",
    "                if matching_path in temp_mask and dict_prediction_train[key][-1]*dict_prediction_train[key][1]>0.1: #iou more than 0.1 is considered correct\n",
    "                    list_labels_auto_train.append(dict_prediction_train[key][-1])\n",
    "                    continue\n",
    "                elif matching_path in temp_mask and dict_prediction_train[key][-1]*dict_prediction_train[key][1]<=0.1:\n",
    "                    list_labels_auto_train.append(0)\n",
    "                    continue\n",
    "            #list_labels_auto_train.append(labels[reordered_key_struct.index(tag_pat)])\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for the testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv = \"annotations_test_dataset.csv\"\n",
    "df_test = pd.read_csv(test_csv,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_struct = [elmt.split(\"\\\\\")[-1][:-4] for elmt in df_test[0]]\n",
    "reordered_key_struct = [elmt[:10]+elmt.split(\"_\")[-1] +\"_\"+ elmt[10] for elmt in key_struct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_prediction_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "path = \"dict_prediction_test.pkl\"\n",
    "with open(path, 'rb') as file:\n",
    "    try:\n",
    "        while True:\n",
    "            dict_prediction_test =  pickle.load(file)\n",
    "    except EOFError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dict_paths_auto_mask_test = {}\n",
    "list_labels_auto_test=[]\n",
    "for temp_mask in tqdm.tqdm(path_testing_masks_auto):\n",
    "    #key_path = temp_mask.split(\"\\\\\")[-1][:-12]\n",
    "    tag_pat = temp_mask.split(\"\\\\\")[-1][:9]+\"_\"+temp_mask.split(\"\\\\\")[-1][:-4].split(\"_\")[3]+\"_\"+temp_mask.split(\"\\\\\")[-1][:-4].split(\"_\")[2] \n",
    "    for temp_mha in path_images:\n",
    "        small_path_mha = temp_mha.split(\"\\\\\")[-1]\n",
    "        if tag_pat in small_path_mha and tag_pat in reordered_key_struct :\n",
    "            dict_paths_auto_mask_test[temp_mask]=temp_mha\n",
    "            for key in list(dict_prediction_test.keys()):\n",
    "                matching_path = key.split(\"\\\\\")[-1].split(\".\")[0] + \"_\" +key.split(\"\\\\\")[-1][-1] + \"_auto_rt_struct.mha\"\n",
    "                if matching_path in temp_mask and dict_prediction_test[key][-1]*dict_prediction_test[key][1]>0.1: #iou more than 0.1 is considered correct\n",
    "                    list_labels_auto_test.append(dict_prediction_test[key][-1])\n",
    "                    continue\n",
    "                elif matching_path in temp_mask and dict_prediction_test[key][-1]*dict_prediction_test[key][1]<=0.1:\n",
    "                    list_labels_auto_test.append(0)\n",
    "                    continue\n",
    "            #list_labels_auto_test.append(labels[reordered_key_struct.index(tag_pat)])\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_le_re = {}\n",
    "for temp_mha in path_images:\n",
    "    parent = os.path.dirname(temp_mha)\n",
    "    for temp_mha_le in path_images_le:\n",
    "        if parent in temp_mha_le:\n",
    "            dict_le_re[temp_mha]=temp_mha_le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_patient = []\n",
    "for elmt in list(dict_paths_auto_mask_test.keys()):\n",
    "    list_patient.append(elmt[:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_patients = np.unique(list_patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cl_features  = pd.read_excel(r\"E:\\ManonData\\keras-retinanet-master\\Clinical_Features_all.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dict = {}\n",
    "for pat in all_patients:\n",
    "    filtered_dict[pat] = list(df_cl_features[['Outcome','specificity']][df_cl_features['UM_ID']==pat].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = pd.DataFrame.from_dict(filtered_dict,columns = ['outcome','specificity'],orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtered_df.to_excel(r'E:\\ManonData\\keras-retinanet-master\\all_datasets\\test_dataset_experiment\\data for sergey\\outcome_specificity_per_patient.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_df = pd.read_excel(r'E:\\ManonData\\keras-retinanet-master\\all_datasets\\test_dataset_experiment\\data for sergey\\data_bbox.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import regionprops\n",
    "\n",
    "list_paths = list(bbox_df[\"Unnamed: 0\"])\n",
    "dict_temp = {}\n",
    "main_path = r\"E:\\ManonData\\keras-retinanet-master\\all_datasets\\test_dataset_experiment\\auto_generated_mask\\\\\"\n",
    "for path in tqdm.tqdm(list_paths):\n",
    "    temp_path = main_path + path\n",
    "    temp_image = sitk.GetArrayFromImage(sitk.ReadImage(temp_path))\n",
    "    props = regionprops(temp_image)\n",
    "    r0, c0, r1, c1 = props[0].bbox\n",
    "    dict_temp[path] = [r0, c0, r1, c1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_sergey = pd.DataFrame.from_dict(dict_temp,columns=['x_min','y_min','x_max','y_max'],orient='index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_df[['x_min','y_min','x_max','y_max']] = df_for_sergey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_df=bbox_df.set_index(\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bbox_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "#for sergey\n",
    "dict_paths_auto_mask_test = {}\n",
    "for temp_mask in tqdm.tqdm(path_testing_masks_auto):\n",
    "    #key_path = temp_mask.split(\"\\\\\")[-1][:-12]\n",
    "    tag_pat = temp_mask.split(\"\\\\\")[-1][:9]+\"_\"+temp_mask.split(\"\\\\\")[-1][:-4].split(\"_\")[3]+\"_\"+temp_mask.split(\"\\\\\")[-1][:-4].split(\"_\")[2] \n",
    "    for temp_mha in path_images:\n",
    "        small_path_mha = temp_mha.split(\"\\\\\")[-1]\n",
    "        if tag_pat in small_path_mha and tag_pat in reordered_key_struct :\n",
    "            temp_mha_le = dict_le_re[temp_mha]\n",
    "#             shutil.copy(temp_mha_le, r\"E:\\ManonData\\keras-retinanet-master\\all_datasets\\test_dataset_experiment\\data for sergey\\\\\")\n",
    "#             shutil.copy(temp_mha, r\"E:\\ManonData\\keras-retinanet-master\\all_datasets\\test_dataset_experiment\\data for sergey\\\\\")\n",
    "            for key in list(dict_prediction_test.keys()):\n",
    "                matching_path = key.split(\"\\\\\")[-1].split(\".\")[0] + \"_\" +key.split(\"\\\\\")[-1][-1] + \"_auto_rt_struct.mha\"\n",
    "                if matching_path in temp_mask and dict_prediction_test[key][1]>0.1: #iou more than 0.1 is considered correct\n",
    "                    dict_paths_auto_mask_test[temp_mask.split(\"\\\\\")[-1]]=[small_path_mha,temp_mha_le.split(\"\\\\\")[-1]]+list(dict_prediction_test[key][0])+[dict_prediction_test[key][1],1,dict_prediction_test[key][-1]]\n",
    "                    continue\n",
    "                elif matching_path in temp_mask and dict_prediction_test[key][1]<=0.1:\n",
    "                    dict_paths_auto_mask_test[temp_mask.split(\"\\\\\")[-1]]=[small_path_mha,temp_mha_le.split(\"\\\\\")[-1]]+list(dict_prediction_test[key][0])+[dict_prediction_test[key][1],0,'na']\n",
    "                    continue\n",
    "            #list_labels_auto_test.append(labels[reordered_key_struct.index(tag_pat)])\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_paths_auto_mask_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load extraction parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramsFile=r\"E:\\ManonData\\keras-retinanet-master\\MR_2D_extraction.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = featureextractor.RadiomicsFeatureExtractor(paramsFile,shape2D=True,force2D=True,force2Ddimension=True,resampledPixelSpacing=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set to all the features\n",
    "\n",
    "extractor.addProvenance(False)\n",
    "extractor.disableAllFeatures()\n",
    "extractor.enableImageTypes(Original={})\n",
    "\n",
    "extractor.enableFeatureClassByName('firstorder', enabled=True)\n",
    "#extractor.enableFeatureClassByName('shape', enabled=False)\n",
    "extractor.enableFeatureClassByName('shape2D', enabled=True)\n",
    "extractor.enableFeatureClassByName('glcm', enabled=True)\n",
    "extractor.enableFeatureClassByName('glrlm', enabled=True)\n",
    "extractor.enableFeatureClassByName('glszm', enabled=True)\n",
    "extractor.enableFeatureClassByName('gldm', enabled=True)\n",
    "extractor.enableFeatureClassByName('ngtdm', enabled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create feature tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features_table(dict_paths):\n",
    "    #initialize table\n",
    "    featureVector = extractor.execute(list(dict_paths.values())[0],list(dict_paths.keys())[0])\n",
    "    temp_dataset =pd.Series(featureVector)\n",
    "    feature_df =pd.DataFrame([temp_dataset],columns=list(featureVector.keys()),index = [list(dict_paths.keys())[0]] )\n",
    "    for temp_mask in tqdm.tqdm(list(dict_paths.keys())[1:]):\n",
    "        featureVector = extractor.execute(dict_paths[temp_mask], temp_mask)\n",
    "        temp_dataset =pd.Series(featureVector)\n",
    "        feature_df.loc[temp_mask]=temp_dataset.values\n",
    "    return feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_true_mask_train_features = generate_features_table(dict_paths_true_train)\n",
    "#df_true_mask_train_features.to_csv(r\"E:\\ManonData\\keras-retinanet-master\\all_datasets\\train_dataset_sergey\\train_features_true_mask.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_true_mask_test_features = generate_features_table(dict_paths_true_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_true_mask_test_features=pd.read_csv(r\"E:\\ManonData\\keras-retinanet-master\\all_datasets\\test_dataset_experiment\\test_features_true_mask.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_auto_mask_train_features = generate_features_table(dict_paths_auto_mask_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_auto_mask_test_features = generate_features_table(dict_paths_auto_mask_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_true_mask_external_features = generate_features_table(dict_paths_true_external)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auto_mask_external_features = generate_features_table(dict_paths_auto_mask_external)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML model and results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pre-processing for auto masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auto_mask_train_features['labels']=list_labels_auto_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling_k_elements(group, k=500):\n",
    "    if len(group) < k:\n",
    "        return group\n",
    "    return group.sample(k)\n",
    "\n",
    "balanced_dataset = df_auto_mask_train_features.groupby('labels').apply(sampling_k_elements).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_dataset = balanced_dataset.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(balanced_dataset['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_labels = balanced_dataset['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_dataset=balanced_dataset.drop(columns = 'labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(balanced_dataset.columns)\n",
    "for idx,temp_type in enumerate(list(balanced_dataset.dtypes)):\n",
    "    if temp_type == 'O':\n",
    "        balanced_dataset[columns[idx]] = balanced_dataset[columns[idx]].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor = balanced_dataset.corr('spearman').abs()\n",
    "upper_tri = cor.where(np.triu(np.ones(cor.shape),k=1).astype(np.bool))\n",
    "to_drop = []\n",
    "for column in tqdm.tqdm(upper_tri.columns):\n",
    "    for row in upper_tri.columns:\n",
    "        if abs(upper_tri[column][row])>0.85:\n",
    "            if np.sum(abs(upper_tri[column])) > np.sum(abs(upper_tri[row])):\n",
    "                to_drop.append(column)\n",
    "            else:\n",
    "                to_drop.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decor_dataset_auto_test = df_auto_mask_test_features.drop(to_drop,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decor_dataset_auto_test.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decor_dataset_auto = balanced_dataset.drop(to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "selector = VarianceThreshold(threshold = 0.01)\n",
    "selector.fit(decor_dataset_auto)\n",
    "thres_dataset_auto = decor_dataset_auto.loc[:, selector.get_support()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thres_dataset_auto_test = decor_dataset_auto_test.loc[:, selector.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thres_dataset_auto_test =thres_dataset_auto_test.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thres_dataset_auto.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for true contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cor = df_true_mask_train_features.corr('spearman').abs()\n",
    "# upper_tri = cor.where(np.triu(np.ones(cor.shape),k=1).astype(np.bool))\n",
    "# to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.85)] #feature with the highest average correlation to the remaining features was removed.\n",
    "# to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## z-score first and remove maybe the ones wich are not normaly distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for radiomics only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#remove patient infos\n",
    "img_paths = df_true_mask_train_features[\"Unnamed: 0\"]\n",
    "img_paths_test = df_true_mask_test_features[\"Unnamed: 0\"]\n",
    "df_true_mask_train_features =df_true_mask_train_features.drop([\"Unnamed: 0\"], axis=1)\n",
    "df_true_mask_test_features=df_true_mask_test_features.drop([\"Unnamed: 0\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths_external = df_true_mask_external_features[\"Unnamed: 0\"]\n",
    "df_true_mask_external_features=df_true_mask_external_features.drop([\"Unnamed: 0\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eliminate non-normal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from scipy import stats ##not a necessary step for xgboost but mandatory for SVM\n",
    "# alpha = 1e-3\n",
    "# non_normal_col = []\n",
    "# for col in tqdm.tqdm(list(df_true_mask_train_features.columns)[1:]):\n",
    "#     k2, p = stats.normaltest(df_true_mask_train_features[col])\n",
    "#     if p > alpha: \n",
    "#         print(col)\n",
    "#         non_normal_col.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_true_mask_train_normal= df_true_mask_train_features.drop(non_normal_col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_true_mask_test_normal= df_true_mask_test_features.drop(non_normal_col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##z-score\n",
    "from scipy.stats import zscore\n",
    "mean_std={}\n",
    "for var in df_true_mask_train_features.columns:\n",
    "    temp_mean = df_true_mask_train_features[var].mean()\n",
    "    temp_std = df_true_mask_train_features[var].std()\n",
    "    mean_std[var]=(temp_mean,temp_std)\n",
    "    df_true_mask_train_features[var] = (df_true_mask_train_features[var]-temp_mean)/temp_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##applied to test set\n",
    "for var in df_true_mask_test_features.columns:\n",
    "    df_true_mask_test_features[var] = (df_true_mask_test_features[var]-mean_std[var][0])/mean_std[var][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##applied to external set\n",
    "for var in df_true_mask_external_features.columns:\n",
    "    df_true_mask_external_features[var] = (df_true_mask_external_features[var]-mean_std[var][0])/mean_std[var][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##variance threshold\n",
    "from sklearn.feature_selection import VarianceThreshold \n",
    "selector = VarianceThreshold(threshold = 0.01)\n",
    "selector.fit(df_true_mask_train_features)\n",
    "thres_dataset_train = df_true_mask_train_features.loc[:, selector.get_support()]\n",
    "thres_dataset_test = df_true_mask_test_features.loc[:, selector.get_support()]\n",
    "thres_dataset_external = df_true_mask_external_features.loc[:, selector.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(selector.get_support())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor = thres_dataset_train.corr('spearman').abs()\n",
    "upper_tri = cor.where(np.triu(np.ones(cor.shape),k=1).astype(np.bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = []\n",
    "for column in upper_tri.columns:\n",
    "    for row in upper_tri.columns:\n",
    "        if upper_tri[column][row]>0.85:\n",
    "            if np.sum(upper_tri[column]) > np.sum(upper_tri[row]): #need to check equivalent function in R cor findcorrelation\n",
    "                to_drop.append(column)\n",
    "            else:\n",
    "                to_drop.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = np.unique(to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decor_dataset = thres_dataset_train.drop(to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with clinical features\n",
    "decor_dataset = pd.concat([decor_dataset,clinical_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decor_dataset_test = thres_dataset_test.drop(to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decor_dataset_test = pd.concat([decor_dataset_test,clinical_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decor_dataset_external = thres_dataset_external.drop(to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(decor_dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(use_label_encoder=False, colsample_bytree=1,\n",
    "  objective= 'binary:logistic',eval_metric = 'logloss', nthread=4, scale_pos_weight=1, seed=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_features_to_select = 1  # Minimum number of features to consider\n",
    "rfecv = RFECV(estimator=model, step=1, cv=StratifiedKFold(10),\n",
    "              scoring='roc_auc',\n",
    "              min_features_to_select=min_features_to_select)\n",
    "rfecv.fit(decor_dataset, true_train_outcome)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(min_features_to_select,\n",
    "               len(rfecv.grid_scores_) + min_features_to_select),\n",
    "         rfecv.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "# min_features_to_select = 1  # Minimum number of features to consider\n",
    "# rfecv = RFECV(estimator=model, step=1, cv=StratifiedKFold(10),\n",
    "#               scoring='roc_auc',\n",
    "#               min_features_to_select=min_features_to_select)\n",
    "# rfecv.fit(decor_dataset, true_train_outcome)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(min_features_to_select,\n",
    "               len(rfecv.grid_scores_) + min_features_to_select),\n",
    "         rfecv.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgb.__version__ former version '1.0.0-SNAPSHOT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(use_label_encoder=False, colsample_bytree=1,\n",
    "  objective= 'binary:logistic',eval_metric = 'logloss', nthread=4, scale_pos_weight=1, seed=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe = RFE(estimator=model,n_features_to_select=8, random_state=0)\n",
    "#rfe = RFE(estimator=RandomForestClassifier(),n_features_to_select=10)\n",
    "n8_features_train_set = rfe.fit_transform(decor_dataset, true_train_outcome)\n",
    "filtered_col = np.extract(rfe.support_, np.array(decor_dataset.columns))\n",
    "n8_features_train_set = pd.DataFrame(data=n8_features_train_set, columns=filtered_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 1000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(2, 20, num = 10)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "\n",
    "# param_test_rf = {\n",
    "#     'rfe__n_features_to_select':[8,10,12],\n",
    "#     'model__n_estimators': n_estimators,\n",
    "#     'model__max_features': max_features,\n",
    "#     'model__max_depth': max_depth,\n",
    "#     'model__min_samples_leaf': min_samples_leaf}\n",
    "param_test_rf = {\n",
    "    'n_estimators': n_estimators,\n",
    "#    'max_features': max_features,\n",
    "    'max_depth': max_depth,\n",
    "    'min_samples_leaf': min_samples_leaf,\n",
    "    'bootstrap':bootstrap\n",
    "}\n",
    "\n",
    "# param_test_xgb = {\n",
    "# 'rfe__n_features_to_select':[6,8,10,12],\n",
    "# 'xgb__max_depth':range(2,4,1),\n",
    "# 'xgb__min_child_weight':range(1,6,2),\n",
    "# 'xgb__n_estimators': range(60, 220, 40),\n",
    "# 'xgb__gamma':[i*0.1 for i in range(3,10)],\n",
    "# 'xgb__learning_rate':[10**(-i) for i in range(3,5)]\n",
    "# #'xgb__weights' : [ 10, 50, 75, 99]\n",
    "# }\n",
    "\n",
    "param_test_xgb = {\n",
    "'max_depth':range(2,4,1),\n",
    "'min_child_weight':range(1,6,2),\n",
    "'n_estimators': [int(x) for x in np.linspace(start = 10, stop = 1000, num = 10)],\n",
    "'gamma':[i*0.1 for i in range(3,10)],\n",
    "'learning_rate':[10**(-i) for i in range(2,7)]\n",
    "#'xgb__weights' : [ 10, 50, 75, 99]\n",
    "}\n",
    "\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#model = RandomForestClassifier()\n",
    "\n",
    "pipeline = Pipeline(steps=[('rfe',rfe),('model',model)])\n",
    "\n",
    "# gsearch1 = GridSearchCV(pipeline, \n",
    "#  param_grid = param_test_rf, scoring='roc_auc',n_jobs=12,iid=False, cv=kfold,verbose=1)\n",
    "\n",
    "# gsearch1.fit(n10_features_train_set, true_train_outcome)\n",
    "gsearch1 = GridSearchCV(model, \n",
    "  param_grid = param_test_xgb, scoring='roc_auc',n_jobs=4,iid=False, cv=kfold,verbose=1)\n",
    "\n",
    "gsearch1.fit(n8_features_train_set, true_train_outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n8_features_test_set = rfe.transform(decor_dataset_test)\n",
    "#n8_features_external_set = rfe.transform(decor_dataset_external)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n8_features_test_set = pd.DataFrame(data=n8_features_test_set, columns=filtered_col)\n",
    "#n8_features_external_set = pd.DataFrame(data=n8_features_external_set, columns=filtered_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#\n",
    "# Create your model here (same as above)\n",
    "#\n",
    "# tuple_objects = (gsearch1,filtered_col,n8_features_train_set,n8_features_test_set)\n",
    "# # Save to file in the current working directory\n",
    "# pkl_filename = r\"E:\\ManonData\\keras-retinanet-master\\examples\\pickle_model_best_xgb_true_labels.pkl\"\n",
    "# with open(pkl_filename, 'wb') as file:\n",
    "#     pickle.dump(tuple_objects, file)\n",
    "\n",
    "# # Load from file\n",
    "# with open(pkl_filename, 'rb') as file:\n",
    "#     gsearch1,filtered_col,n8_features_train_set,n8_features_test_set = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf\n",
    "# {'bootstrap': True,\n",
    "#  'max_depth': 16,\n",
    "#  'min_samples_leaf': 2,\n",
    "#  'n_estimators': 670}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for radiomics only\n",
    "# gsearch1.best_params_\n",
    "# {'gamma': 0.6000000000000001,\n",
    "#  'learning_rate': 0.01,\n",
    "#  'max_depth': 3,\n",
    "#  'min_child_weight': 1,\n",
    "#  'n_estimators': 560}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for radiomics and clinical features\n",
    "# gsearch1.best_params_\n",
    "# {'gamma': 0.8,\n",
    "#  'learning_rate': 0.01,\n",
    "#  'max_depth': 3,\n",
    "#  'min_child_weight': 3,\n",
    "#  'n_estimators': 890}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##for the automated segmentation\n",
    "kfold = KFold(n_splits=10, random_state=42)\n",
    "\n",
    "gsearch2 = GridSearchCV(estimator = xgb.XGBClassifier( colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test1, scoring='roc_auc',n_jobs=8,iid=False, cv=kfold,verbose=1)\n",
    "\n",
    "gsearch2.fit(thres_dataset_auto, list(balanced_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch1.best_score_ #0.8673408532469921 for ground truth with 10 features #0.8942350794061321 with no feature selection 0.9167289576454515 with 8 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch2.best_score_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator = gsearch1.best_estimator_\n",
    "best_estimator.feature_names = filtered_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator_auto = gsearch2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10,20)\n",
    "xgb.plot_importance(best_estimator.get_booster()) #to double check\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_train=best_estimator.predict_proba(n8_features_train_set)\n",
    "proba_test=best_estimator.predict_proba(n8_features_test_set)\n",
    "#proba_external=best_estimator.predict_proba(n8_features_external_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_train_auto=best_estimator_auto.predict_proba(thres_dataset_auto)\n",
    "proba_test_auto=best_estimator_auto.predict_proba(thres_dataset_auto_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_external_binary_outcome = []\n",
    "for elmt in true_external_outcome:\n",
    "    if elmt == 1 or elmt == 2 or elmt == 3:\n",
    "        true_external_binary_outcome.append(1)\n",
    "    else:\n",
    "        true_external_binary_outcome.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(use_label_encoder=False, colsample_bytree=1,\n",
    "  objective= 'binary:logistic',eval_metric = 'logloss', nthread=4, scale_pos_weight=1, seed=27,gamma=0.6,learning_rate=0.01, max_depth=3,min_child_weight=1,n_estimators=560)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#also test the full test dataset and the external dataset here\n",
    "cv = StratifiedKFold(n_splits=10,random_state =42)\n",
    "\n",
    "\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "tprs_test = []\n",
    "aucs_test = []\n",
    "mean_fpr_test = np.linspace(0, 1, 100)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "for i, (train, test) in enumerate(cv.split(n8_features_train_set, true_train_outcome)):\n",
    "    model.fit(np.array(n8_features_train_set)[train], np.array(true_train_outcome)[train])\n",
    "#     viz = plot_roc_curve(model, np.array(n8_features_train_set)[test], np.array(true_train_outcome)[test],\n",
    "#                          name='ROC fold {}'.format(i),\n",
    "#                          alpha=0.3, lw=1, ax=ax)\n",
    "    proba_test =  model.predict_proba(np.array(n8_features_train_set)[test])\n",
    "    fpr_test, tpr_test, thresholds_test = sklearn.metrics.roc_curve( np.array(true_train_outcome)[test],np.array(proba_test[:,1]))\n",
    "    interp_tpr = np.interp(mean_fpr, fpr_test, tpr_test)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "    roc_auc_test = sklearn.metrics.auc(fpr_test, tpr_test)\n",
    "    aucs.append(roc_auc_test)\n",
    "    \n",
    "    proba_test_full =  model.predict_proba(np.array(n8_features_test_set))\n",
    "    fpr_test_full, tpr_test_full, thresholds_test_full = sklearn.metrics.roc_curve( np.array(true_test_outcome),np.array(proba_test_full[:,1]))\n",
    "    interp_tpr_test = np.interp(mean_fpr_test, fpr_test_full, tpr_test_full)\n",
    "    interp_tpr_test[0] = 0.0\n",
    "    tprs_test.append(interp_tpr_test)\n",
    "    roc_auc_test_full = sklearn.metrics.auc(fpr_test_full, tpr_test_full)\n",
    "    aucs_test.append(roc_auc_test_full)\n",
    "    \n",
    "ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "        label='Chance', alpha=.8)\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = sklearn.metrics.auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "ax.plot(mean_fpr, mean_tpr, color='b',\n",
    "        label=r'Mean ROC test (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "        lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "ax.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.3,\n",
    "                label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "# mean_tpr_test = np.mean(tprs_test, axis=0)\n",
    "# mean_tpr_test[-1] = 1.0\n",
    "# mean_auc_test = sklearn.metrics.auc(mean_fpr_test, mean_tpr_test)\n",
    "# std_auc_test = np.std(aucs_test)\n",
    "# ax.plot(mean_fpr_test, mean_tpr_test, color='g',\n",
    "#         label=r'Mean ROC validation (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc_test, std_auc_test),\n",
    "#         lw=2, alpha=.8)\n",
    "\n",
    "# std_tpr_test = np.std(tprs_test, axis=0)\n",
    "# tprs_upper = np.minimum(mean_tpr_test + std_tpr_test, 1)\n",
    "# tprs_lower = np.maximum(mean_tpr_test - std_tpr_test, 0)\n",
    "# ax.fill_between(mean_fpr_test, tprs_lower, tprs_upper, color='green', alpha=.3,\n",
    "#                 label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05])\n",
    "ax.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "np.random.seed(32)\n",
    "def bootstrap(x, f, nsamples=1000):\n",
    "    stats = [f(x[np.random.randint(x.shape[0], size=x.shape[0])]) for _ in range(nsamples)]\n",
    "    return np.percentile(stats, (2.5, 97.5))\n",
    "\n",
    "#def bootstrap_auc(clf, X_train, y_train, X_test, y_test,X_external,y_external, nsamples=1000):\n",
    "clf, X_train, y_train, X_test, y_test,X_external,y_external = model,np.array(n8_features_train_set), np.array(true_train_outcome), np.array(n8_features_test_set), np.array(true_test_outcome),np.array(n8_features_external_set),np.array(true_external_binary_outcome)\n",
    "clf.fit(X_train, y_train)\n",
    "nsamples=1000\n",
    "auc_values = []\n",
    "auc_values_external=[]\n",
    "\n",
    "accuracy_values = []\n",
    "accuracy_values_external=[]\n",
    "\n",
    "precision_values = []\n",
    "precision_values_external=[]\n",
    "\n",
    "recall_values = []\n",
    "recall_values_external=[]\n",
    "\n",
    "tprs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "tprs_external = []\n",
    "mean_fpr_external = np.linspace(0, 1, 100)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "for b in tqdm.tqdm(range(nsamples)):\n",
    "    idx_test = np.random.randint(X_test.shape[0], size=X_test.shape[0])\n",
    "    idx_external = np.random.randint(X_external.shape[0], size=X_external.shape[0])\n",
    "    pred = clf.predict_proba(X_test[idx_test])[:, 1]\n",
    "    accuracy_values.append(accuracy_score(y_test[idx_test],(np.array(pred)>0.5).astype(int)))\n",
    "    precision_values.append(precision_score(y_test[idx_test],(np.array(pred)>0.5).astype(int)))\n",
    "    recall_values.append(recall_score(y_test[idx_test],(np.array(pred)>0.5).astype(int)))\n",
    "                         \n",
    "    pred_external= clf.predict_proba(X_external[idx_external])[:, 1]\n",
    "    accuracy_values_external.append(accuracy_score(y_external[idx_external],(np.array(pred_external)>0.5).astype(int)))\n",
    "    precision_values_external.append(precision_score(y_external[idx_external],(np.array(pred_external)>0.5).astype(int)))\n",
    "    recall_values_external.append(recall_score(y_external[idx_external],(np.array(pred_external)>0.5).astype(int)))                                             \n",
    "\n",
    "    fpr_test, tpr_test, thresholds_test = sklearn.metrics.roc_curve( y_test[idx_test], pred)\n",
    "    interp_tpr = np.interp(mean_fpr, fpr_test, tpr_test)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "\n",
    "    fpr_external, tpr_external, thresholds_external = sklearn.metrics.roc_curve(y_external[idx_external], pred_external)\n",
    "    interp_tpr_external = np.interp(mean_fpr_external, fpr_external, tpr_external)\n",
    "    interp_tpr_external[0] = 0.0\n",
    "    tprs_external.append(interp_tpr_external)\n",
    "\n",
    "    roc_auc = sklearn.metrics.auc(fpr_test, tpr_test)\n",
    "    roc_auc_external = sklearn.metrics.auc(fpr_external, tpr_external)\n",
    "    auc_values.append(roc_auc)\n",
    "    auc_values_external.append(roc_auc_external)\n",
    "\n",
    "ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "    label='Chance', alpha=.8)\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = sklearn.metrics.auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(auc_values)\n",
    "ax.plot(mean_fpr, mean_tpr, color='b',\n",
    "        label=r'Mean ROC test (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "        lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "ax.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.3,\n",
    "                label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "mean_tpr_external = np.mean(tprs_external, axis=0)\n",
    "mean_tpr_external[-1] = 1.0\n",
    "mean_auc_external = sklearn.metrics.auc(mean_fpr_external, mean_tpr_external)\n",
    "std_auc_external = np.std(auc_values_external)\n",
    "ax.plot(mean_fpr_external, mean_tpr_external, color='g',\n",
    "        label=r'Mean ROC external dataset (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc_external, std_auc_external),\n",
    "        lw=2, alpha=.8)\n",
    "\n",
    "std_tpr_external = np.std(tprs_external, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr_external + std_tpr_external, 1)\n",
    "tprs_lower = np.maximum(mean_tpr_external - std_tpr_external, 0)\n",
    "ax.fill_between(mean_fpr_external, tprs_lower, tprs_upper, color='green', alpha=.3,\n",
    "                label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05])\n",
    "ax.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "print(np.percentile(auc_values, (2.5, 97.5)),np.percentile(auc_values_external, (2.5, 97.5)))\n",
    "print(np.mean(precision_values),np.percentile(precision_values, (2.5, 97.5)),np.mean(precision_values_external),np.percentile(precision_values_external, (2.5, 97.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(accuracy_values),np.percentile(accuracy_values, (2.5, 97.5)),np.mean(accuracy_values_external),np.percentile(accuracy_values_external, (2.5, 97.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(recall_values),np.percentile(recall_values, (2.5, 97.5)),np.mean(recall_values_external),np.percentile(recall_values_external, (2.5, 97.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fpr_train, tpr_train, thresholds_test = sklearn.metrics.roc_curve(true_train_outcome,np.array(proba_train[:,1]))\n",
    "roc_auc_train = sklearn.metrics.auc(fpr_train, tpr_train)\n",
    "fpr_test, tpr_test, thresholds_test = sklearn.metrics.roc_curve(true_test_outcome,np.array(proba_test[:,1]))\n",
    "roc_auc_test = sklearn.metrics.auc(fpr_test, tpr_test)\n",
    "# fpr_external, tpr_external, thresholds_external = sklearn.metrics.roc_curve(true_external_binary_outcome,np.array(proba_external[:,1]))\n",
    "# roc_auc_external = sklearn.metrics.auc(fpr_external, tpr_external)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.rcParams['font.size'] = '14'\n",
    "lw = 2\n",
    "plt.plot(fpr_train, tpr_train,\n",
    "         label='ROC curve train dataset (area = {0:0.2f})'\n",
    "               ''.format(roc_auc_train),\n",
    "         color='darkorange', linewidth=2)\n",
    "plt.plot(fpr_test, tpr_test,\n",
    "         label='ROC curve test dataset (area = {0:0.2f})'\n",
    "               ''.format(roc_auc_test),\n",
    "         color='darkblue', linewidth=2)\n",
    "# plt.plot(fpr_external, tpr_external,\n",
    "#          label='ROC curve external dataset (area = {0:0.2f})'\n",
    "#                ''.format(roc_auc_external),\n",
    "#          color='green', linewidth=2)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic LN vs no LN')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report #recall is sensitivity\n",
    "print(classification_report(true_test_outcome,(np.array(proba_test[:,1])>0.5).astype(int), target_names=[\"benign\",\"malignant\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(true_external_binary_outcome,(np.array(proba_external[:,1])>0.5).astype(int), target_names=[\"benign\",\"malignant\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def print_confusion_matrix(true_labels, predicted_labels, class_names, figsize = (6,5), fontsize=14,normalize=True):\n",
    "    \"\"\"Prints a confusion matrix, as returned by sklearn.metrics.confusion_matrix, as a heatmap.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    confusion_matrix: numpy.ndarray\n",
    "        The numpy.ndarray object returned from a call to sklearn.metrics.confusion_matrix. \n",
    "        Similarly constructed ndarrays can also be used.\n",
    "    class_names: list\n",
    "        An ordered list of class names, in the order they index the given confusion matrix.\n",
    "    figsize: tuple\n",
    "        A 2-long tuple, the first value determining the horizontal size of the ouputted figure,\n",
    "        the second determining the vertical size. Defaults to (10,7).\n",
    "    fontsize: int\n",
    "        Font size for axes labels. Defaults to 14.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.figure.Figure\n",
    "        The resulting confusion matrix figure\n",
    "    \"\"\"\n",
    "    sns.set(font_scale=1.4)\n",
    "    confusion_matrix= sklearn.metrics.confusion_matrix(true_labels,predicted_labels)\n",
    "    if normalize:\n",
    "        confusion_matrix = confusion_matrix.astype('float') / confusion_matrix.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "    df_cm = pd.DataFrame(\n",
    "        confusion_matrix, index=class_names, columns=class_names, \n",
    "    )\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    try:\n",
    "        if normalize:\n",
    "            fmt = '.2f' \n",
    "            heatmap = sns.heatmap(df_cm, annot=True, fmt=fmt,cmap=\"Blues\",vmin=0, vmax=1)\n",
    "        else:\n",
    "            fmt = 'd' \n",
    "            heatmap = sns.heatmap(df_cm, annot=True, fmt=fmt,cmap=\"Blues\",vmax=np.max(confusion_matrix),vmin=0)\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "      \n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "fig = print_confusion_matrix(true_labels=true_test_outcome, predicted_labels = (np.array(proba_test[:,1])>0.1).astype(int), class_names=[\"benign\",\"malignant\"])\n",
    "#print(accuracy_score(y_true_patient,bin_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_train, tpr_train, thresholds_test = sklearn.metrics.roc_curve(list(balanced_labels),np.array(proba_train_auto[:,1]))\n",
    "roc_auc_train = sklearn.metrics.auc(fpr_train, tpr_train)\n",
    "fpr_test, tpr_test, thresholds_test = sklearn.metrics.roc_curve(list_labels_auto_test,np.array(proba_test_auto[:,1]))\n",
    "roc_auc_test = sklearn.metrics.auc(fpr_test, tpr_test)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.rcParams['font.size'] = '14'\n",
    "lw = 2\n",
    "plt.plot(fpr_train, tpr_train,\n",
    "         label='ROC curve train dataset (area = {0:0.2f})'\n",
    "               ''.format(roc_auc_train),\n",
    "         color='darkorange', linewidth=2)\n",
    "plt.plot(fpr_test, tpr_test,\n",
    "         label='ROC curve test dataset (area = {0:0.2f})'\n",
    "               ''.format(roc_auc_test),\n",
    "         color='darkblue', linewidth=2)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic LN vs no LN')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = print_confusion_matrix(true_labels=list_labels_auto_test, predicted_labels = (np.array(proba_test_auto[:,1])>0.5).astype(int), class_names=[\"benign\",\"malignant\"],normalize=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(lbl_full_dataset)/len(lbl_full_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "estimator = RandomForestClassifier()\n",
    "selector = RFE(estimator, n_features_to_select=10, step=1)\n",
    "selector = selector.fit(thres_dataset, lbl_full_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features10_dataset = selector.transform(thres_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
